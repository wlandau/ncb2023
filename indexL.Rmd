---
title: "Fold change example"
author: "Luwis Diya"
output: html_document
bibliography: bibliography.bib
---

```{r setup, include = FALSE}
library(coda)
library(rjags)
library(brms)
library(tidyverse)
library(broom.mixed)
knitr::opts_chunk$set(echo = TRUE)
set.seed(0)
setwd("/Users/ldiya/Library/CloudStorage/OneDrive-JNJ/projects/NCB Bayesian Training/Will code")
```

## About

Consider a pre-clinical animal study (mice) with one treatment group and one placebo group. The outcome measure is qPCR gene expression on the log scale, and the goal is to estimate fold change of the outcome for treatment versus placebo. This report compares a simple frequentist model and the analogous Bayesian model in this analysis. In each case, the fold change is not an explicit parameter in the model and needs to be calculated by transforming other model parameters.

## Data

We simulate 10 mice from a normal distribution for each of the two groups.

Quantity | placebo | Treatment
---|---|---
Mean | 3 | 4
Standard deviation | 1 | 1

In our dataset, the `y` column is the outcome we are modeling, and the `i` column is the group designation.

```{r}
library(tidyverse)
placebo <- tibble(
  y = rnorm(n = 10, mean = 3, sd = 1),
  i = 1
)
treatment <- tibble(
  y = rnorm(n = 10, mean = 4, sd = 1),
  i = 2
)
data <- bind_rows(placebo, treatment)
data
```

## Frequentist analysis

The frequentist model is a simple cell means model with one mean for each group. Below, $i = 1, I$ ($I = 2$) is the group designation, $j = 1, \ldots, J$ ($J = 10$) is the index of the mouse, $y_{ij}$ is the response of group $i$ mouse $j$, $\mu_i$ is the unknown mean parameter of group $i$, $\sigma$ is the unknown residual standard deviation, and $\stackrel{\text{ind}}{\sim}$ is shorthand to indicate independent and identically distributed quantities.

$$
\begin{aligned}
y_{ij} \stackrel{\text{ind}}{\sim} \text{Normal}(\mu_i, \sigma^2)
\end{aligned}
$$
The fold change we want to estimate is the ratio of group means:

$$
\text{Fold change} = \frac{\mu_2}{\mu_1}
$$

The joint density of $y = (y_{11}, \ldots, y_{IJ})$ given the parameters can be written as

$$
p_{\mu_1, \mu_2, \sigma}(y) = \prod_{j = 1}^{J} \frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{1}{2} \left (\frac{y_{ij} - \mu_i}{\sigma} \right )^2}
$$

with likelihood $L(\mu_1, \mu_2, \sigma | y) = p_{\mu_1, \mu_2, \sigma}(y)$. The fold change we want to estimate is 

We fit this model using `lm()` in R and note the estimate and standard error of each mean (placebo and treatment).

```{r}
fit_frequentist <- lm(y ~ 0 + i, data = mutate(data, i = ordered(i))) %>%
  broom::tidy() %>%
  rename(standard_error = std.error) %>%
  select(term, estimate, standard_error)

fit_frequentist
```

We can use the delta method ([@beyene2005]) to approximate the mean and 95% confidence interval of the fold change $\mu_2/\mu_1$. The implementation below assumes independence between $\mu_1$ and $\mu_2$, which is consistent with the model.

```{r}
delta_method <- function(
  estimate_treatment,
  estimate_placebo,
  standard_error_treatment,
  standard_error_placebo,
  alpha = 0.05
) {
  a <- estimate_treatment
  b <- estimate_placebo
  se_a <- standard_error_treatment
  se_b <- standard_error_placebo
  theta <- a / b
  v11 <- se_a ^ 2
  v22 <- se_b ^ 2
  z <- qnorm(p = alpha / 2, lower.tail = FALSE)
  sigma <- sqrt((1 / (b ^ 2)) * (v11 + (theta ^ 2) * v22))
  lower <- theta - z * sigma
  upper <- theta + z * sigma
  tibble(estimate = theta, lower = lower, upper = upper)
}

index_treatment <- which(fit_frequentist$term == "i2")
index_placebo <- which(fit_frequentist$term == "i1")

delta_approximation <- delta_method(
  estimate_treatment = fit_frequentist$estimate[index_treatment],
  estimate_placebo = fit_frequentist$estimate[index_placebo],
  standard_error_treatment = fit_frequentist$standard_error[index_treatment],
  standard_error_placebo = fit_frequentist$standard_error[index_placebo],
  alpha = 0.05
)

delta_approximation
```

We can alternatively use Fieller's method ([@fieller1940], [@cordell1999], [@beyene2005]) to approximate the same quantities. The implementation below assumes independence between $\mu_1$ and $\mu_2$, which is consistent with the model.

```{r}
fieller_method <- function(
  estimate_treatment,
  estimate_placebo,
  standard_error_treatment,
  standard_error_placebo,
  alpha = 0.05
) {
  a <- estimate_treatment
  b <- estimate_placebo
  se_a <- standard_error_treatment
  se_b <- standard_error_placebo
  theta <- a / b
  v11 <- se_a ^ 2
  v22 <- se_b ^ 2
  z <- qnorm(p = alpha / 2, lower.tail = FALSE)
  k <- (z ^ 2 * v22) / b ^ 2
  estimate <- theta + (k / (1 - k)) * theta
  margin <- z / (b * (1 - k)) * sqrt(v11 + theta ^ 2 * v22 - k * v11)
  bound1 <- estimate - margin
  bound2 <- estimate + margin
  lower <- pmin(bound1, bound2)
  upper <- pmax(bound1, bound2)
  tibble(estimate = estimate, lower = lower, upper = upper)
}

fieller_approximation <- fieller_method(
  estimate_treatment = fit_frequentist$estimate[index_treatment],
  estimate_placebo = fit_frequentist$estimate[index_placebo],
  standard_error_treatment = fit_frequentist$standard_error[index_treatment],
  standard_error_placebo = fit_frequentist$standard_error[index_placebo],
  alpha = 0.05
)

fieller_approximation
```

## Bayesian model

The Bayesian model is the same as the frequentist one except that we treat parameters as if they were random variables and we assign them prior distributions.

$$
\begin{aligned}
&y_{ij} \stackrel{\text{ind}}{\sim} \text{Normal}(\mu_i, \sigma^2) \\
&\qquad \mu_i \stackrel{\text{ind}}{\sim} \text{Normal}(0, s_\mu^2) \\
&\qquad \sigma \sim \text{Uniform}(0, s_\sigma)
\end{aligned}
$$

Above, $s_\mu$ and $s_\sigma$ are constant hyperparameters that placebo the diffuseness of the priors. If we lack prior information, diffuse priors (e.g. large values of $s_\mu$ and $s_\sigma$) may be appropriate if this is computationally feasible.

We express the model in the JAGS code below.^[The normal distribution in JAGS accepts the precision as the second argument instead of the variance or standard deviation.]

```{r}
code <- "
model{
  for (n in 1:N) {
    y[n] ~ dnorm(mu[i[n]], (1 / (sigma * sigma)))
  }
  for (j in 1:I) {
    mu[j] ~ dnorm(0, (1 / (s_mu * s_mu)))
  }
  sigma ~ dunif(0, s_sigma)
}
"
```

We save this code to a file.

```{r, include = FALSE}
writeLines(code, "model.jags")
```

We fit the model in `brms`, obtain posterior samples of the parameters, and check convergence diagnostics.

```{r, output = FALSE, warning = FALSE}
#Priors
prior <- get_prior(y ~ 0 + i, data = mutate(data, i = ordered(i)),
                    family = gaussian())
## define a prior on all population-level effects at once
prior$prior[1] <- "normal(0,10)"
## define a prior on the residual sd
prior$prior[4] <- "uniform(0.001,10)"
## verify that the priors indeed found their way into Stan's model code
make_stancode(y ~ 0 + i, data = mutate(data, i = ordered(i)),
                    family = gaussian(), 
                    prior = prior)
#Fit the model
fit_bayesian0 <- brm(y ~ 0 + i, data = mutate(data, i = ordered(i)),
                    family = gaussian(), prior = prior,
                    warmup=2e3,iter=4e3,chains=4,thin=1 
                    )
#Update function:
fit_bayesian <- update(fit_bayesian0,warmup=4e3,iter=8e3,chains=4,thin=2)
fit_bayesian %>% tidy() %>% 
                 rename(standard_error = std.error, lcl=conf.low, ucl=conf.high) %>%
                 select(term, estimate, standard_error,lcl,ucl)
#Convergence diagnostics
launch_shinystan(fit_bayesian)
#Posterior samples 
ps <- as_draws_df(fit_bayesian)
```

We check convergence. Rhat should be below 1.01, and effective sample size should be at least 100 times the number of chains (in our case, 400).

Computing the mean and 95% posterior interval of the fold change $\mu_2/\mu_1$ is easy in the Bayesian paradigm. We simply take the ratio of the posterior samples of $\mu_2$ and $\mu_1$. Unlike the delta method and Fieller's method, this method in the Bayesian paradigm is exact.

```{r}
bayesian_estimate <- as_draws_df(fit_bayesian) %>% 
                     summarise(estimate=mean(b_i1/b_i2),
                     lower = quantile((b_i1/b_i2), prob = 0.025),
                     upper = quantile((b_i1/b_i2), prob = 0.975) )
bayesian_estimate
```

Now, we can compare intervals.

```{r}
estimates <- bind_rows(
  delta = delta_approximation,
  fieller = fieller_approximation,
  bayes = bayesian_estimate,
  .id = "method"
)
estimates
```

```{r}
library(ggplot2)
ggplot(estimates) +
  geom_point(aes(x = method, y = estimate, color = method)) +
  geom_errorbar(aes(x = method, ymin = lower, ymax = upper, color = method)) +
  expand_limits(y = 0)
```

## Remarks

The fold change on the log scale is not the only possible measure of differential expression in animal studies, but we include it here because convenient frequentist approximations exist and match the results of an equivalent Bayesian analysis with diffuse priors. For more complicated estimands, frequentist approximations may not be feasible, but the Bayesian paradigm still just as easily yields a valid marginal posterior distribution.

## References